# -*- coding: utf-8 -*-
"""Prompt

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rx39SHK7TUnovql_9KtGOnry3VKJQCCR
"""

# 📌 Gerekli kütüphanelerin yüklenmesi
!pip install transformers accelerate --quiet

# 🚀 Model ve tokenizer yükleniyor
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

model_name = "google/flan-t5-large"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# 🎯 Prompt tanımı (İngilizce)
prompt = "Describe in detail how I will look, my profession, and lifestyle 20 years from now."

# ✏️ Giriş verisinin hazırlanması
inputs = tokenizer(prompt, return_tensors="pt")

# 🔮 Tahminin üretilmesi
output = model.generate(
    input_ids=inputs["input_ids"],
    max_new_tokens=200,
    temperature=0.7,
    do_sample=True,
    top_k=50,
    top_p=0.95,
    repetition_penalty=1.2
)

# 🖨️ Çıktının yazdırılması
response = tokenizer.decode(output[0], skip_special_tokens=True)
print("🔮 Prediction:\n", response)

# Gerekli kütüphaneleri yükle (ilk defa çalıştırıyorsan)
!pip install diffusers transformers accelerate scipy safetensors

from diffusers import StableDiffusionPipeline
import torch

# Modeli yükle
model_id = "runwayml/stable-diffusion-v1-5"
device = "cuda" if torch.cuda.is_available() else "cpu"

pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipe = pipe.to(device)

# Görsel oluşturmak istediğin metin
prompt = ("A futuristic peaceful eco-friendly city with green skyscrapers, clean energy, "
          "a happy person living a vegan lifestyle, walking in a park, bright sunlight, "
          "highly detailed, photorealistic")

# Görsel oluştur
image = pipe(prompt, guidance_scale=7.5).images[0]

# Görseli göster
image.show()

!pip install diffusers transformers accelerate scipy safetensors

from huggingface_hub import login

hf_token = "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"  # buraya token'ını yapıştır
login(token=hf_token)

from diffusers import StableDiffusionPipeline
import torch

pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
).to("cuda")

prompt = "a futuristic cityscape under the stars, neon lights, flying cars, cyberpunk style, ultra-detailed"
image = pipe(prompt).images[0]
image.show()

prompt = "A colorful vegetarian meal on a wooden table, fresh vegetables, clean natural lighting, top-down view, high-resolution, artistic style"

image = pipe(prompt).images[0]
image.show()  # Görseli Jupyter/Colab içinde gösterir

# Opsiyonel: Görseli kaydetmek istersen
image.save("text_to_image_result.png")

from google.colab import files
files.download("text_to_image_result.png")

!pip install gradio --quiet

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from diffusers import StableDiffusionPipeline
import torch

# Model ve tokenizer yükle (daha önceden yaptığın gibi)
model_name = "google/flan-t5-large"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

device = "cuda" if torch.cuda.is_available() else "cpu"
pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16).to(device)

def generate_detailed_text(simple_prompt):
    prompt = simple_prompt + " Describe in detail how I will look, my profession, and lifestyle 20 years from now."
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    outputs = model.generate(
        input_ids=inputs["input_ids"],
        max_new_tokens=200,
        temperature=0.7,
        do_sample=True,
        top_k=50,
        top_p=0.95,
        repetition_penalty=1.2
    )
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response

def generate_image_from_text(detailed_prompt):
    image = pipe(detailed_prompt, guidance_scale=7.5).images[0]
    return image

import gradio as gr

def generate_all(prompt):
    detailed_text = generate_detailed_text(prompt)
    image = generate_image_from_text(detailed_text)
    return image, detailed_text

iface = gr.Interface(
    fn=generate_all,
    inputs=gr.Textbox(lines=2, placeholder="Basit tanımı yazınız..."),
    outputs=[gr.Image(type="pil"), gr.Textbox(label="Detaylandırılmış Açıklama")],
    title="Akıllı Metinden Görsele Dönüştürücü",
    description="Basit bir metin girin, 20 yıl sonraki detaylı açıklama ve görselini oluşturun."
)

iface.launch()

!pip install gradio transformers diffusers accelerate scipy safetensors --quiet

import gradio as gr
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from diffusers import StableDiffusionPipeline
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"

# Dil modeli
model_name = "google/flan-t5-large"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)

# Görsel modeli
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16 if device=="cuda" else torch.float32,
).to(device)

def generate_detailed_text(simple_prompt):
    prompt = simple_prompt + " Describe in detail how I will look, my profession, and lifestyle 20 years from now."
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    outputs = model.generate(
        input_ids=inputs["input_ids"],
        max_new_tokens=100,
        temperature=0.8,
        do_sample=True,
        top_k=30,
        top_p=0.9,
        repetition_penalty=1.1
    )
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response

def generate_image_from_text(detailed_prompt):
    image = pipe(detailed_prompt, guidance_scale=7.5).images[0]
    return image

def generate_all(prompt):
    try:
        detailed_text = generate_detailed_text(prompt)
    except Exception as e:
        return None, f"Dil modeli hatası: {str(e)}"

    try:
        image = generate_image_from_text(detailed_text)
    except Exception as e:
        return None, f"Görsel modeli hatası: {str(e)}"

    return image, detailed_text

iface = gr.Interface(
    fn=generate_all,
    inputs=gr.Textbox(lines=2, placeholder="Basit tanımı yazınız..."),
    outputs=[gr.Image(type="pil"), gr.Textbox(label="Detaylandırılmış Açıklama")],
    title="Akıllı Metinden Görsele Dönüştürücü",
    description="Basit bir metin girin, 20 yıl sonraki detaylı açıklama ve görselini oluşturun."
)

iface.launch()

import gradio as gr
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from diffusers import StableDiffusionPipeline
import torch

# --- Dil modeli yükle ---
model_name = "google/flan-t5-large"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# --- Görsel modeli yükle ---
device = "cuda" if torch.cuda.is_available() else "cpu"
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16 if device=="cuda" else torch.float32
).to(device)

# --- Dil modelinden detaylı metin üreten fonksiyon ---
def generate_detailed_text(prompt):
    expanded_prompt = f"Describe in detail how this scene will look 20 years from now: {prompt}"
    inputs = tokenizer(expanded_prompt, return_tensors="pt")
    output = model.generate(
        input_ids=inputs["input_ids"],
        max_new_tokens=200,
        temperature=0.7,
        do_sample=True,
        top_k=50,
        top_p=0.95,
        repetition_penalty=1.2
    )
    detailed_text = tokenizer.decode(output[0], skip_special_tokens=True)
    return detailed_text

# --- Görsel modeliyle görsel üreten fonksiyon ---
def generate_image_from_text(detailed_prompt):
    image = pipe(detailed_prompt, guidance_scale=7.5).images[0]
    return image

# --- Ana fonksiyon: önce metni detaylandır, sonra görseli oluştur ---
def generate_all(prompt):
    try:
        detailed_text = generate_detailed_text(prompt)
    except Exception as e:
        return None, f"Dil modeli hatası: {str(e)}"

    try:
        image = generate_image_from_text(detailed_text)
    except Exception as e:
        return None, f"Görsel modeli hatası: {str(e)}"

    return image, detailed_text

# --- Gradio arayüzü ---
iface = gr.Interface(
    fn=generate_all,
    inputs=gr.Textbox(lines=2, placeholder="Basit tanımı yazınız..."),
    outputs=[gr.Image(type="pil"), gr.Textbox(label="Detaylandırılmış Açıklama")],
    title="Akıllı Metinden Görsele Dönüştürücü",
    description="Basit bir metin girin, 20 yıl sonraki detaylı açıklama ve görselini oluşturur."
)

iface.launch()

!pip install --upgrade gradio

import gradio as gr

def process_audio(audio):
    if audio is None:
        return "Hiç ses kaydedilmedi."
    return "Ses başarıyla alındı!"

iface = gr.Interface(
    fn=process_audio,
    inputs=gr.Audio(),  # source parametresi yok
    outputs="text"
)

iface.launch()